{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of classification.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shovalkooba/shoval1/blob/master/cifar10_with_roc-very%20slow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp80hJV6qmzl",
        "colab_type": "text"
      },
      "source": [
        "confusion matrix plot function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feFKZJucqm89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "================\n",
        "Confusion matrix\n",
        "================\n",
        "\n",
        "Example of confusion matrix usage to evaluate the quality\n",
        "of the output of a classifier on the iris data set. The\n",
        "diagonal elements represent the number of points for which\n",
        "the predicted label is equal to the true label, while\n",
        "off-diagonal elements are those that are mislabeled by the\n",
        "classifier. The higher the diagonal values of the confusion\n",
        "matrix the better, indicating many correct predictions.\n",
        "\n",
        "The figures show the confusion matrix with and without\n",
        "normalization by class support size (number of elements\n",
        "in each class). This kind of normalization can be\n",
        "interesting in case of class imbalance to have a more\n",
        "visual interpretation of which class is being misclassified.\n",
        "\n",
        "Here the results are not as good as they could be as our\n",
        "choice for the regularization parameter C was not the best.\n",
        "In real life applications this parameter is usually chosen\n",
        "using :ref:`grid_search`.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#print(__doc__)\n",
        "\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        normed_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        normed_cm = normed_cm*100;\n",
        "        print(\"Normalized confusion matrix\")\n",
        "        print(normed_cm)\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.figure(figsize=(20,20))\n",
        "    plt.imshow(normed_cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j,i, format(normed_cm[i, j], fmt)+'%\\n('+(format(cm[i, j], 'd'))+')',\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.gcf().subplots_adjust(bottom=0.3)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO-hctZCqnFj",
        "colab_type": "text"
      },
      "source": [
        "import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM9oERWKqnM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential, Model\n",
        "import keras.layers as layers\n",
        "from keras.utils import to_categorical\n",
        "from keras import optimizers\n",
        "from keras.models import model_from_json\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D,Flatten, Dense, Activation, MaxPooling2D, Dropout, BatchNormalization\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from numpy import argmax\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQHfAzQFqnTR",
        "colab_type": "text"
      },
      "source": [
        "import pic sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z80EVMq4qnau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "\n",
        "# Change labels to one-hot encoding\\n\",\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "# Print shapes\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V65Ou-yqnic",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "test config model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S68xS134qnqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #num_of_clss =  10          # number of classes\n",
        "#hidden_size =        256    # number of neurons in the hidden layer\n",
        "#lr =        0.00009        # learning rate \n",
        "#beta_1 =   0.9              # beta 1 - for adam optimizer\n",
        "#beta_2 =      0.99           # beta 2 - for adam optimizer\n",
        "#epsilon =         1e-8       # epsilon - for adam optimizer\n",
        "#epochs =               10  # number of epochs \n",
        "#bs =                  64   # batch size\n",
        "\n",
        "#from keras.layers import Dense, Flatten, Activation\n",
        "\n",
        "#model = Sequential()\n",
        "\n",
        "#model.add(Flatten())\n",
        "#model.add(Dense(hidden_size))\n",
        "#model.add(Activation('tanh'))\n",
        "#model.add(Dense(hidden_size))\n",
        "#model.add(Activation('sigmoid'))\n",
        "#model.add(Dense(num_of_clss))\n",
        "#model.add(Activation('softmax'))\n",
        "\n",
        "num_of_clss =   10          # number of classes\n",
        "\n",
        "lr =      1e-4               # learning rate \n",
        "beta_1 =      0.9           # beta 1 - for adam optimizer\n",
        "beta_2 = 0.99        # beta 2 - for adam optimizer\n",
        "epsilon =    1e-8            # epsilon - for adam optimizer\n",
        "epochs =    50           # number of epochs \n",
        "bs =       16        # batch size\n",
        "dp=0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaIzI1YmZKpD",
        "colab_type": "text"
      },
      "source": [
        "cnn config model- not touch!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epiO2dFKZKvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "num_of_clss =   10          # number of classes\n",
        "\n",
        "lr =      1e-4               # learning rate \n",
        "beta_1 =      0.9           # beta 1 - for adam optimizer\n",
        "beta_2 = 0.99        # beta 2 - for adam optimizer\n",
        "epsilon =    1e-8            # epsilon - for adam optimizer\n",
        "epochs =    50           # number of epochs \n",
        "bs =       16        # batch size\n",
        "dp=0.5\n",
        "\"\"\"\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(dp))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(dp))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(dp))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='sigmoid',))\n",
        "model.add(Dense(10, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MLpdpaDqnwn",
        "colab_type": "text"
      },
      "source": [
        "train model and get results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5xLT5Mjqn2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# define the optimizer and compile the model\n",
        "adam = optimizers.Adam(lr=lr, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model, iterating on the data in batches of 64 samples\n",
        "history = model.fit(x_train, y_train, validation_split=0.3, epochs=epochs, batch_size=bs)\n",
        "\n",
        "\n",
        "# plot train and validation loss \n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show(); plt.close()\n",
        "\n",
        "\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print results\n",
        "print('test loss:', test_loss)\n",
        "print('test accuracy:', test_acc)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RV0ADCLFu1r",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0TNRZ1uFvXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(x_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egKvt1iaqn88",
        "colab_type": "text"
      },
      "source": [
        "draw confusion matrix and summerize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9Z8TmqqqoDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(np.argmax(y_test,axis=1), np.argmax(np.round(y_pred),axis=1))\n",
        "labels = ['class ' + str(i) for i in range(num_of_clss)] \n",
        "plot_confusion_matrix(cm,labels,title='Confusion Matrix',normalize=True)\n",
        "\n",
        "\n",
        "\n",
        "# Summerize the model arhiteture and parameters\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdZbhjpUcwGk",
        "colab_type": "text"
      },
      "source": [
        "*binary* division for 0-else "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyZ0AsWIjZHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_auc = [None] * len(y_test)\n",
        "y_pred_auc = [None] * len(y_pred)\n",
        "\n",
        "for i in range(0,len(y_test)):\n",
        "  if(argmax(y_test[i])==0):\n",
        "    y_test_auc[i]=0\n",
        "  else:\n",
        "   y_test_auc[i]=1\n",
        "\n",
        "\n",
        "for i in range(0,len(y_pred)):\n",
        "  if(argmax(y_pred[i])==0):\n",
        "    y_pred_auc[i]=0\n",
        "  else:\n",
        "   y_pred_auc[i]=1\n",
        "\n",
        "\n",
        "y_pred_auc= to_categorical(y_pred_auc)\n",
        "y_test_auc= to_categorical(y_test_auc)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LcGTqMtHUy3",
        "colab_type": "text"
      },
      "source": [
        "compute ROC curve for model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1_K1wPKJ-tL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "# Compute ROC curve and ROC area for each class\n",
        "\n",
        "for i in range(2):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_auc[:, i], y_pred_auc[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_auc.ravel(), y_pred_auc.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7zBCMWnSh8k",
        "colab_type": "text"
      },
      "source": [
        "plot ROC curve for model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBNaqC4zOa1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(fpr[i], tpr[i], color='darkorange',\n",
        "         lw=0.5, label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=0.5, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}