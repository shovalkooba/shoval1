{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exc2 part 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shovalkooba/shoval1/blob/master/exe2_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp80hJV6qmzl",
        "colab_type": "text"
      },
      "source": [
        "Confusion matrix plot function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feFKZJucqm89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "================\n",
        "Confusion matrix\n",
        "================\n",
        "\n",
        "Example of confusion matrix usage to evaluate the quality\n",
        "of the output of a classifier on the iris data set. The\n",
        "diagonal elements represent the number of points for which\n",
        "the predicted label is equal to the true label, while\n",
        "off-diagonal elements are those that are mislabeled by the\n",
        "classifier. The higher the diagonal values of the confusion\n",
        "matrix the better, indicating many correct predictions.\n",
        "\n",
        "The figures show the confusion matrix with and without\n",
        "normalization by class support size (number of elements\n",
        "in each class). This kind of normalization can be\n",
        "interesting in case of class imbalance to have a more\n",
        "visual interpretation of which class is being misclassified.\n",
        "\n",
        "Here the results are not as good as they could be as our\n",
        "choice for the regularization parameter C was not the best.\n",
        "In real life applications this parameter is usually chosen\n",
        "using :ref:`grid_search`.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#print(__doc__)\n",
        "\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        normed_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        normed_cm = normed_cm*100;\n",
        "        print(\"Normalized confusion matrix\")\n",
        "        print(normed_cm)\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.figure(figsize=(20,20))\n",
        "    plt.imshow(normed_cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j,i, format(normed_cm[i, j], fmt)+'%\\n('+(format(cm[i, j], 'd'))+')',\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.gcf().subplots_adjust(bottom=0.3)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRUMeIPmj4xB",
        "colab_type": "text"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLZY273Hj5cP",
        "colab_type": "code",
        "outputId": "6b34612e-4b5c-4b80-c15f-9bbd1f13658d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential, Model\n",
        "import keras.layers as layers\n",
        "from keras.utils import to_categorical\n",
        "from keras import optimizers\n",
        "from keras.models import model_from_json\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D,Flatten, Dense, Activation, MaxPooling2D, Dropout, BatchNormalization\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve, auc"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6u7hk-_j360",
        "colab_type": "text"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI7705ValnKH",
        "colab_type": "code",
        "outputId": "ac91a9f9-3554-4f92-f9a9-d6a30679f656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "\n",
        "# Change labels to one-hot encoding\\n\",\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "# Print shapes\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "x_test shape: (10000, 32, 32, 3)\n",
            "y_train shape: (50000, 10)\n",
            "y_test shape: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW4J_QpOj3DN",
        "colab_type": "text"
      },
      "source": [
        "Define Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zusbhm_fnZ7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_of_clss =   10          # number of classes\n",
        "\n",
        "lr =      1e-4               # learning rate \n",
        "beta_1 =      0.9           # beta 1 - for adam optimizer\n",
        "beta_2 = 0.99        # beta 2 - for adam optimizer\n",
        "epsilon =    1e-8            # epsilon - for adam optimizer\n",
        "epochs =    50           # number of epochs \n",
        "bs =       16        # batch size\n",
        "dp=0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8VZyVhonhaZ",
        "colab_type": "text"
      },
      "source": [
        "Network layes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9E4RIjrnpPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(dp))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(dp))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(dp))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='sigmoid',))\n",
        "model.add(Dense(10, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmIuhpu2oVww",
        "colab_type": "text"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzicMwDGoJ1h",
        "colab_type": "code",
        "outputId": "b8f66d64-be90-42f5-da31-0e6f22caacd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# define the optimizer and compile the model\n",
        "adam = optimizers.Adam(lr=lr, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model, iterating on the data in batches of 64 samples\n",
        "history = model.fit(x_train, y_train, validation_split=0.3, epochs=epochs, batch_size=bs)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 35000 samples, validate on 15000 samples\n",
            "Epoch 1/50\n",
            "35000/35000 [==============================] - 189s 5ms/step - loss: 2.3239 - acc: 0.1105 - val_loss: 2.2925 - val_acc: 0.1384\n",
            "Epoch 2/50\n",
            "35000/35000 [==============================] - 186s 5ms/step - loss: 2.3046 - acc: 0.1119 - val_loss: 2.2997 - val_acc: 0.1398\n",
            "Epoch 3/50\n",
            "35000/35000 [==============================] - 190s 5ms/step - loss: 2.2673 - acc: 0.1359 - val_loss: 2.1547 - val_acc: 0.1934\n",
            "Epoch 4/50\n",
            "35000/35000 [==============================] - 192s 5ms/step - loss: 2.0816 - acc: 0.2176 - val_loss: 1.9780 - val_acc: 0.2569\n",
            "Epoch 5/50\n",
            "35000/35000 [==============================] - 185s 5ms/step - loss: 1.9434 - acc: 0.2770 - val_loss: 1.8941 - val_acc: 0.2985\n",
            "Epoch 6/50\n",
            "35000/35000 [==============================] - 186s 5ms/step - loss: 1.7925 - acc: 0.3351 - val_loss: 1.6883 - val_acc: 0.3692\n",
            "Epoch 7/50\n",
            "35000/35000 [==============================] - 184s 5ms/step - loss: 1.6785 - acc: 0.3774 - val_loss: 1.6348 - val_acc: 0.4036\n",
            "Epoch 8/50\n",
            "35000/35000 [==============================] - 183s 5ms/step - loss: 1.5611 - acc: 0.4270 - val_loss: 1.5542 - val_acc: 0.4380\n",
            "Epoch 9/50\n",
            "35000/35000 [==============================] - 191s 5ms/step - loss: 1.4357 - acc: 0.4721 - val_loss: 1.5686 - val_acc: 0.4455\n",
            "Epoch 10/50\n",
            "35000/35000 [==============================] - 197s 6ms/step - loss: 1.3358 - acc: 0.5104 - val_loss: 1.3216 - val_acc: 0.5251\n",
            "Epoch 11/50\n",
            "35000/35000 [==============================] - 198s 6ms/step - loss: 1.2416 - acc: 0.5524 - val_loss: 1.2677 - val_acc: 0.5505\n",
            "Epoch 12/50\n",
            "35000/35000 [==============================] - 199s 6ms/step - loss: 1.1764 - acc: 0.5789 - val_loss: 1.0741 - val_acc: 0.6185\n",
            "Epoch 13/50\n",
            "35000/35000 [==============================] - 195s 6ms/step - loss: 1.1186 - acc: 0.5982 - val_loss: 1.1259 - val_acc: 0.6052\n",
            "Epoch 14/50\n",
            "35000/35000 [==============================] - 194s 6ms/step - loss: 1.0721 - acc: 0.6171 - val_loss: 1.1207 - val_acc: 0.6111\n",
            "Epoch 15/50\n",
            "35000/35000 [==============================] - 189s 5ms/step - loss: 1.0324 - acc: 0.6321 - val_loss: 0.9478 - val_acc: 0.6661\n",
            "Epoch 16/50\n",
            "35000/35000 [==============================] - 192s 5ms/step - loss: 0.9992 - acc: 0.6435 - val_loss: 0.9826 - val_acc: 0.6584\n",
            "Epoch 17/50\n",
            "35000/35000 [==============================] - 195s 6ms/step - loss: 0.9669 - acc: 0.6582 - val_loss: 0.9311 - val_acc: 0.6717\n",
            "Epoch 18/50\n",
            "35000/35000 [==============================] - 187s 5ms/step - loss: 0.9421 - acc: 0.6672 - val_loss: 0.9342 - val_acc: 0.6712\n",
            "Epoch 19/50\n",
            "35000/35000 [==============================] - 186s 5ms/step - loss: 0.9164 - acc: 0.6764 - val_loss: 0.8473 - val_acc: 0.7004\n",
            "Epoch 20/50\n",
            "35000/35000 [==============================] - 186s 5ms/step - loss: 0.8934 - acc: 0.6860 - val_loss: 0.8844 - val_acc: 0.6927\n",
            "Epoch 21/50\n",
            "35000/35000 [==============================] - 187s 5ms/step - loss: 0.8683 - acc: 0.6938 - val_loss: 0.8172 - val_acc: 0.7129\n",
            "Epoch 22/50\n",
            "35000/35000 [==============================] - 183s 5ms/step - loss: 0.8550 - acc: 0.6968 - val_loss: 0.8256 - val_acc: 0.7133\n",
            "Epoch 23/50\n",
            "35000/35000 [==============================] - 181s 5ms/step - loss: 0.8338 - acc: 0.7068 - val_loss: 0.8055 - val_acc: 0.7187\n",
            "Epoch 24/50\n",
            "35000/35000 [==============================] - 180s 5ms/step - loss: 0.8149 - acc: 0.7143 - val_loss: 0.7890 - val_acc: 0.7245\n",
            "Epoch 25/50\n",
            "35000/35000 [==============================] - 181s 5ms/step - loss: 0.8033 - acc: 0.7159 - val_loss: 0.8212 - val_acc: 0.7130\n",
            "Epoch 26/50\n",
            "35000/35000 [==============================] - 186s 5ms/step - loss: 0.7896 - acc: 0.7209 - val_loss: 0.7498 - val_acc: 0.7391\n",
            "Epoch 27/50\n",
            "35000/35000 [==============================] - 182s 5ms/step - loss: 0.7796 - acc: 0.7268 - val_loss: 0.7865 - val_acc: 0.7273\n",
            "Epoch 28/50\n",
            "35000/35000 [==============================] - 182s 5ms/step - loss: 0.7655 - acc: 0.7301 - val_loss: 0.7383 - val_acc: 0.7441\n",
            "Epoch 29/50\n",
            "35000/35000 [==============================] - 179s 5ms/step - loss: 0.7490 - acc: 0.7352 - val_loss: 0.7313 - val_acc: 0.7456\n",
            "Epoch 30/50\n",
            "35000/35000 [==============================] - 182s 5ms/step - loss: 0.7420 - acc: 0.7404 - val_loss: 0.6961 - val_acc: 0.7576\n",
            "Epoch 31/50\n",
            "35000/35000 [==============================] - 182s 5ms/step - loss: 0.7357 - acc: 0.7418 - val_loss: 0.7655 - val_acc: 0.7391\n",
            "Epoch 32/50\n",
            "35000/35000 [==============================] - 188s 5ms/step - loss: 0.7218 - acc: 0.7471 - val_loss: 0.7025 - val_acc: 0.7535\n",
            "Epoch 33/50\n",
            "35000/35000 [==============================] - 184s 5ms/step - loss: 0.7166 - acc: 0.7498 - val_loss: 0.6939 - val_acc: 0.7607\n",
            "Epoch 34/50\n",
            "35000/35000 [==============================] - 185s 5ms/step - loss: 0.7037 - acc: 0.7533 - val_loss: 0.7175 - val_acc: 0.7538\n",
            "Epoch 35/50\n",
            "35000/35000 [==============================] - 184s 5ms/step - loss: 0.6957 - acc: 0.7551 - val_loss: 0.7140 - val_acc: 0.7566\n",
            "Epoch 36/50\n",
            "35000/35000 [==============================] - 179s 5ms/step - loss: 0.6912 - acc: 0.7565 - val_loss: 0.6973 - val_acc: 0.7600\n",
            "Epoch 37/50\n",
            "35000/35000 [==============================] - 179s 5ms/step - loss: 0.6772 - acc: 0.7623 - val_loss: 0.6942 - val_acc: 0.7623\n",
            "Epoch 38/50\n",
            "35000/35000 [==============================] - 191s 5ms/step - loss: 0.6749 - acc: 0.7618 - val_loss: 0.6411 - val_acc: 0.7789\n",
            "Epoch 39/50\n",
            "35000/35000 [==============================] - 190s 5ms/step - loss: 0.6664 - acc: 0.7645 - val_loss: 0.6657 - val_acc: 0.7725\n",
            "Epoch 40/50\n",
            "35000/35000 [==============================] - 182s 5ms/step - loss: 0.6673 - acc: 0.7661 - val_loss: 0.6500 - val_acc: 0.7801\n",
            "Epoch 41/50\n",
            "35000/35000 [==============================] - 189s 5ms/step - loss: 0.6568 - acc: 0.7715 - val_loss: 0.6586 - val_acc: 0.7748\n",
            "Epoch 42/50\n",
            "35000/35000 [==============================] - 186s 5ms/step - loss: 0.6493 - acc: 0.7719 - val_loss: 0.6474 - val_acc: 0.7777\n",
            "Epoch 43/50\n",
            "35000/35000 [==============================] - 188s 5ms/step - loss: 0.6424 - acc: 0.7749 - val_loss: 0.6517 - val_acc: 0.7757\n",
            "Epoch 44/50\n",
            "35000/35000 [==============================] - 186s 5ms/step - loss: 0.6373 - acc: 0.7760 - val_loss: 0.6198 - val_acc: 0.7887\n",
            "Epoch 45/50\n",
            "35000/35000 [==============================] - 186s 5ms/step - loss: 0.6324 - acc: 0.7775 - val_loss: 0.6431 - val_acc: 0.7786\n",
            "Epoch 46/50\n",
            "35000/35000 [==============================] - 186s 5ms/step - loss: 0.6283 - acc: 0.7792 - val_loss: 0.6246 - val_acc: 0.7838\n",
            "Epoch 47/50\n",
            "35000/35000 [==============================] - 186s 5ms/step - loss: 0.6214 - acc: 0.7817 - val_loss: 0.6348 - val_acc: 0.7886\n",
            "Epoch 48/50\n",
            "35000/35000 [==============================] - 187s 5ms/step - loss: 0.6144 - acc: 0.7862 - val_loss: 0.6469 - val_acc: 0.7799\n",
            "Epoch 49/50\n",
            "35000/35000 [==============================] - 189s 5ms/step - loss: 0.6152 - acc: 0.7842 - val_loss: 0.6258 - val_acc: 0.7875\n",
            "Epoch 50/50\n",
            "35000/35000 [==============================] - 180s 5ms/step - loss: 0.6100 - acc: 0.7877 - val_loss: 0.6439 - val_acc: 0.7857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgx10wVmyCfF",
        "colab_type": "text"
      },
      "source": [
        "Plot Train and Validation loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCOJuIl6yPKQ",
        "colab_type": "code",
        "outputId": "f9c51142-d3fa-48da-d9af-572b0f201c44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show(); plt.close()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrsbTdfOocYw",
        "colab_type": "text"
      },
      "source": [
        "Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCe9mTe4oy67",
        "colab_type": "code",
        "outputId": "f3010193-942f-4b6d-fb6e-486ce75a8d20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print results\n",
        "print('test loss:', test_loss)\n",
        "print('test accuracy:', test_acc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 11s 1ms/step\n",
            "test loss: 0.7079502778530121\n",
            "test accuracy: 0.7591\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAaV8CF8oQJ7",
        "colab_type": "text"
      },
      "source": [
        "Predict on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ste3IfZYpLrl",
        "colab_type": "code",
        "outputId": "29c556ca-326c-49c3-baab-fb5b76dad954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(np.argmax(y_test,axis=1), np.argmax(np.round(y_pred),axis=1))\n",
        "labels = ['class ' + str(i) for i in range(num_of_clss)] \n",
        "plot_confusion_matrix(cm,labels,title='Confusion Matrix',normalize=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-ec044f86289f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'class '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_of_clss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Confusion Matrix'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: plot_confusion_matrix() got an unexpected keyword argument 'title'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn3mF4HopYwS",
        "colab_type": "text"
      },
      "source": [
        "Sunnerize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfIVp-HIqWd3",
        "colab_type": "code",
        "outputId": "b9475305-b4b1-4909-a970-a3e4efe87b49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# Summerize the model arhiteture and parameters\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_3 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 12)                9420      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                130       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 9,550\n",
            "Trainable params: 9,550\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}